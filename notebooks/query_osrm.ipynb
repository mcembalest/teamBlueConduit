{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "desperate-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from blue_conduit_spatial.utilities import *\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "announced-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_dictionary = {'pid': 'pid', 'Property Z': 'Property Zip Code', 'Owner Type': 'Owner Type',\n",
    "                       'Owner Stat': 'Owner State', 'Homestead': 'Homestead', 'Homestea_1': 'Homestead Percent',\n",
    "                       'HomeSEV': 'HomeSEV', 'Land Value': 'Land Value', 'Land Impro': 'Land Improvements Value',\n",
    "                       'Residentia': 'Residential Building Value', 'Resident_1': 'Residential Building Style',\n",
    "                       'Commercial': 'Commercial Building Value', 'Building S': 'Building Storeys',\n",
    "                       'Parcel Acr': 'Parcel Acres', 'Rental': 'Rental', 'Use Type': 'Use Type',\n",
    "                       'Prop Class': 'Prop Class', 'Old Prop c': 'Old Prop class', 'Year Built': 'Year Built',\n",
    "                       'USPS Vacan': 'USPS Vacancy', 'Zoning': 'Zoning', 'Future Lan': 'Future Landuse',\n",
    "                       'DRAFT Zone': 'DRAFT Zone', 'Housing Co': 'Housing Condition 2012',\n",
    "                       'Housing _1': 'Housing Condition 2014', 'Commerci_1': 'Commercial Condition 2013',\n",
    "                       'Latitude': 'Latitude', 'Longitude': 'Longitude', 'Hydrant Ty': 'Hydrant Type',\n",
    "                       'Ward': 'Ward', 'PRECINCT': 'PRECINCT', 'CENTRACT': 'CENTRACT', 'CENBLOCK': 'CENBLOCK',\n",
    "                       'SL_Type': 'SL_Type', 'SL_Type2': 'SL_Type2', 'SL_Lead': 'SL_Lead', 'Ed_July': 'Ed_July',\n",
    "                       'Ed_March': 'Ed_March', 'Last_Test': 'Last_Test', 'Max_Lead': 'Max_Lead',\n",
    "                       'Med_Lead': 'Med_Lead', 'Num_Tests': 'Num_Tests', 'Res_Test': 'Res_Test',\n",
    "                       'Sen_Test': 'Sen_Test', 'SL_private': 'SL_private_inspection',\n",
    "                       'B_median_a': 'B_median_age_all_women', 'B_median_1': 'B_median_age_all_men', \n",
    "                       'B_median_2': 'B_median_age_all', 'B_median_3': 'B_median_age_all_women_white',\n",
    "                       'B_median_4': 'B_median_age_all_men_white', 'B_median_5': 'B_median_age_all_white',\n",
    "                       'B_median_6': 'B_median_age_all_women_black', 'B_median_7': 'B_median_age_all_men_black',\n",
    "                       'B_median_8': 'B_median_age_all_black', 'B_total_bl': 'B_total_black_pop',\n",
    "                       'B_total_wh': 'B_total_white_pop', 'B_married_': 'B_married_couples',\n",
    "                       'B_single_w': 'B_single_women', 'B_marrie_1': 'B_married_couples_white',\n",
    "                       'B_single_1': 'B_single_women_white', 'B_marrie_2': 'B_married_couples_black',\n",
    "                       'B_single_2': 'B_single_women_black', 'B_marrie_3': 'B_married_couples_w_children',\n",
    "                       'B_single_m': 'B_single_mothers_w_children', 'B_househol': 'B_households_w_elderly',\n",
    "                       'B_househod': 'B_househod_no_elderly', 'B_aggregat': 'B_aggregate_income',\n",
    "                       'B_speak_sp': 'B_speak_spanish', 'B_speak_on': 'B_speak_only_english',\n",
    "                       'B_no_engli': 'B_no_english', 'B_hispanic': 'B_hispanic_household',\n",
    "                       'B_imputed_': 'B_imputed_rent', 'B_impute_1': 'B_imputed_value',\n",
    "                       'known_priv': 'known_private_sl', 'known_publ': 'known_public_sl', 'hydrovac': 'hydrovac',\n",
    "                       'sl_priva_1': 'sl_private_type', 'sl_public_': 'sl_public_type', 'created_at': 'created_at',\n",
    "                       'source': 'source', 'hv_visit': 'hv_visit', 'sl_visit': 'sl_visit', 'replaced': 'replaced',\n",
    "                       'dangerous': 'dangerous', 'geometry': 'geometry'}\n",
    "sl_df = gpd.read_file('../data/raw/flint_sl_materials/')\n",
    "sl_df = sl_df.rename(col_name_dictionary, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driven-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_df = sl_df[sl_df['Longitude'].isna()==False]\n",
    "#sl_df[['Longitude', 'Latitude']]\n",
    "sl_df['longlatstr'] = sl_df['Longitude'].round(6).astype(str) + ',' + sl_df['Latitude'].round(6).astype(str)\n",
    "#sl_df['longlatstr']\n",
    "sl_df = sl_df[~pd.isnull(sl_df.dangerous)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recorded-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haversine Max: 19.0465 km; Min: 0.0000\n",
      "Haversine: Mean=4.6467 km; SD=2.3708 km\n",
      "Size: 0.80 GB\n",
      "CPU times: user 19.7 s, sys: 2.44 s, total: 22.2 s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics.pairwise import euclidean_distances, haversine_distances\n",
    "N_have = 10000\n",
    "sl_df_coord = sl_df[['Latitude', 'Longitude']].apply(np.radians)\n",
    "#sl_dists = euclidean_distances(sl_df_coord[:N])\n",
    "try:\n",
    "    del have_dists\n",
    "except:\n",
    "    pass\n",
    "\n",
    "have_dists = haversine_distances(sl_df_coord[:N_have])\n",
    "\n",
    "#print(f\"Euclidean Max: {(sl_dists*6371).max():0.4f} km; Min: {(sl_dists*6371).min():0.4f}\")\n",
    "#print(f\"Euclidean: Mean={(sl_dists*6371).mean():0.4f} km; SD={(sl_dists*6371).std():0.4f} km\")\n",
    "\n",
    "print(f\"Haversine Max: {(have_dists*6371).max():0.4f} km; Min: {(have_dists*6371).min():0.4f}\")\n",
    "print(f\"Haversine: Mean={(have_dists*6371).mean():0.4f} km; SD={(have_dists*6371).std():0.4f} km\")\n",
    "\n",
    "print(f\"Size: {have_dists.nbytes*1e-9:0.2f} GB\")\n",
    "\n",
    "# Save out haversine distances\n",
    "idx2pid = {idx: sl_df.iloc[i]['pid'] for i, idx in enumerate(sl_df_coord.index)}\n",
    "np.savez(\"../data/processed/haversine_dists.npz\", haversine_distances = have_dists, \n",
    "        idx2pid = idx2pid, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-thailand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "integral-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = \"54.144.55.140\"\n",
    "\n",
    "\n",
    "#calculate_street_distance(0, [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "announced-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadDistanceMatrix:\n",
    "    def __init__(self, N, df):\n",
    "        self.road_dist_arr = self._create_road_dist_array(N)\n",
    "        self.N = self.road_dist_arr.shape[0]\n",
    "        self.lat_long_df = df[['Latitude', 'Longitude']]\n",
    "        self.pids = df[['pid']]\n",
    "        \n",
    "        # Set up error tracking for largest number of points queried\n",
    "        self.max_query = 0\n",
    "        \n",
    "        \n",
    "    def fit(self, base_dists, ip, limit=0.5):\n",
    "        \"\"\"Fits road distance matrix\"\"\"\n",
    "        have_dists_adj = self._convert_subset_baseline_dists(base_dists, N_road=self.N)\n",
    "        self.lat_long_df = self.lat_long_df.iloc[ : self.N]\n",
    "        self.populate_road_dist_matrix(have_dists_adj, ip, limit)\n",
    "        self.limit=limit\n",
    "        \n",
    "    def save(self, filepath):\n",
    "        idx2pid = {idx: self.pids.iloc[i]['pid'] for i, idx in enumerate(self.lat_long_df.index)}\n",
    "        np.savez(filepath, road_distances = self.road_dist_arr, idx2pid = idx2pid, limit=self.limit, allow_pickle=True)\n",
    "        \n",
    "        \n",
    "    def populate_road_dist_matrix(self, base_dists, ip, limit=0.5):\n",
    "        \"\"\"Populates the road distance array\"\"\"\n",
    "        for i in range(self.N):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Finished Row {i}\")\n",
    "            idx = np.argwhere(base_dists[i] < limit).flatten()\n",
    "            n_query = len(idx)\n",
    "            if n_query > 0:\n",
    "                if n_query > self.max_query:\n",
    "                    self.max_query = n_query\n",
    "                x = RoadDistanceMatrix.calculate_street_distance(i, idx, ip_add=ip, df=self.lat_long_df)\n",
    "            else:\n",
    "                x = []\n",
    "            self.road_dist_arr[i][idx] = x\n",
    "        \n",
    "    def _create_road_dist_array(self, N_road=10):\n",
    "        road_dist_arr = np.ones(N_road**2, dtype='float64').reshape(N_road, N_road) * 1e5\n",
    "        return road_dist_arr\n",
    "\n",
    "    def _convert_subset_baseline_dists(self, dists, N_road=10):\n",
    "        \"\"\"Converts haversine distance matrix to be in km and subset to same size as road array\"\"\"\n",
    "        return dists[:N_road, :N_road] * 6371 # 6371 is radius of earth in km\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_long_lat_string(df, j):\n",
    "        \"\"\"Helper method to concatenate strings into OSM-accepted format\"\"\"\n",
    "        long_lat_str =  str(df.iloc[j]['Longitude'].round(6)) + ',' + str(df.iloc[j]['Latitude'].round(6))\n",
    "        return long_lat_str\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_street_distance(i, j_list, ip_add, df, how='walking'):\n",
    "        \"\"\"Returns street distance time in seconds\"\"\"\n",
    "\n",
    "        # Find origin lat/long list\n",
    "        i_long_lat = RoadDistanceMatrix.create_long_lat_string(df, i)\n",
    "\n",
    "        # Find longitude/latitude pairs as a list\n",
    "        #long_lat_list = [ll_str(j) for j in j_list]\n",
    "\n",
    "        longlat_concatstr = ''\n",
    "        for i, c in enumerate(j_list):\n",
    "            if i == 0:\n",
    "                longlat_concatstr = RoadDistanceMatrix.create_long_lat_string(df, c)\n",
    "            else:\n",
    "                longlat_concatstr += ';' + RoadDistanceMatrix.create_long_lat_string(df, c)\n",
    "\n",
    "\n",
    "        url = f\"http://{ip_add}:5000/table/v1/{how}/{i_long_lat};{longlat_concatstr}?sources=0\"\n",
    "        r = requests.get(url)\n",
    "        output = r.json()\n",
    "\n",
    "        return np.array(output['durations'][0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accessory-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blue_conduit_spatial.distance_matrix import RoadDistanceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "photographic-conducting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Row 0\n",
      "CPU times: user 293 ms, sys: 20.9 ms, total: 314 ms\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rdmat = RoadDistanceMatrix(N=20, df=sl_df)\n",
    "rdmat.fit(have_dists, ip=ip, limit=0.1)\n",
    "#rdmat.save(\"../data/processed/road_dists.npz\")\n",
    "\n",
    "#RoadDistanceMatrix.calculate_street_distance(0, [1,2,3], ip_add=ip, df=sl_df[['Latitude', 'Longitude']], how='walking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "corporate-wholesale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdmat.max_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "modified-williams",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Road dist. matrix size: 0.00 GB.\n",
      "CPU times: user 122 ms, sys: 742 µs, total: 123 ms\n",
      "Wall time: 612 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0. , 46.7, 46.9, 49. ,  0. , 49.8, 46.1, 44.2, 44. , 44.1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "limit = 0.5\n",
    "idx_list = []\n",
    "for i in range(N_road):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    idx = np.argwhere(new_y[i] * 6371 < limit).flatten()\n",
    "    if len(idx) > 0:\n",
    "        x = calculate_street_distance(i, idx)\n",
    "    else:\n",
    "        x = []\n",
    "    road_dist_arr[i][idx] = x\n",
    "\n",
    "print(f\"Road dist. matrix size: {road_dist_arr.nbytes*1e-9:0.2f} GB.\")\n",
    "road_dist_arr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-fairy",
   "metadata": {},
   "source": [
    "### DEPRECATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "inclusive-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'durations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mstreet_distance\u001b[0;34m(i, j, ip_add, df, how)\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'durations'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import math\n",
    "ip = \"54.144.55.140\"\n",
    "def street_distance(i, j, ip_add=ip, df=sl_df[['Latitude', 'Longitude']], how='walking'):\n",
    "    \"\"\"Returns street distance time in seconds\"\"\"\n",
    "    def ll_str(j):\n",
    "        return str(df.iloc[j]['Longitude'].round(6)) + ',' + str(df.iloc[j]['Latitude'].round(6))\n",
    "    \n",
    "    #tot_idx = j - i\n",
    "    #iters = math.ceil(tot_idx / 100) ** 2\n",
    "    #step_size = 100\n",
    "   # \n",
    "   # row_it = 0\n",
    "    #i_idx = i\n",
    "    #j_idx = i + step_size\n",
    "    ##for it in range(iters):\n",
    "     #   if j_idx > j:\n",
    "     #       row_it += 1\n",
    "     #       i_idx = row_it * step_size\n",
    "     #       j_idx = i + step_size\n",
    "     #   else:\n",
    "     #       i_idx = \n",
    "        \n",
    "    i_long_lat = str(df.iloc[i]['Longitude'].round(6)) + ',' + str(df.iloc[i]['Latitude'].round(6))\n",
    "\n",
    "    latlonglist = [ll_str(x) for x in range(i+1, j)]\n",
    "\n",
    "    longstr = ''\n",
    "    for i, c in enumerate(latlonglist):\n",
    "        if i == 0:\n",
    "            longstr = c\n",
    "        else:\n",
    "            longstr += ';' + c\n",
    "\n",
    "    url = f\"http://{ip_add}:5000/table/v1/{how}/{i_long_lat};{longstr}\"#\"?sources=0\"\n",
    "    r = requests.get(url)\n",
    "    output = r.json()\n",
    "    \n",
    "    return output['durations']#[0] #[1]\n",
    "#n = street_distance(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "upset-capital",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(n).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ultimate-charleston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.23 s, sys: 0 ns, total: 8.23 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 100\n",
    "road_dist_array = np.zeros(N**2).reshape(N, N)\n",
    "for i in range(N):\n",
    "    #for j in range(N):\n",
    "    #    if have_dists[i][j] * 6371 > 0.75:\n",
    "    #        road_dist_array[i][j] = 1e5\n",
    "    #    else:\n",
    "    #        road_dist_array[i][j] = street_distance(i, j)\n",
    "    road_dist_array[i] = street_distance(i, N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "approximate-genome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0. ,   0. ,  46.7, ..., 345.8, 377.2, 372.8],\n",
       "       [  0. ,  35.9,   0. , ..., 363.5, 394.9, 396.4],\n",
       "       [  0. ,  43.6,  73.4, ..., 350.8, 382.2, 354.7],\n",
       "       ...,\n",
       "       [  0. , 365.1, 362. , ...,  66.7,   0. ,  80.7],\n",
       "       [  0. , 376.4, 375.3, ..., 116.6,  75. ,   0. ],\n",
       "       [  0. , 362.4, 359.3, ...,  91.7,  94.3,  74.3]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road_dist_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quantitative-bhutan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "utility-composer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 ms, sys: 688 µs, total: 15.3 ms\n",
      "Wall time: 11.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 100\n",
    "limit = 0.5\n",
    "for i in range(N):\n",
    "    idx = np.argwhere(have_dists[i] * 6371 < limit).flatten()\n",
    "    #x = street_distance_v2(i, idx)\n",
    "    \n",
    "#idx.shape\n",
    "#idx_1 = np.argwhere(idx[:,0] == 0)\n",
    "#idx[idx_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "agreed-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://54.144.55.140:5000/table/v1/driving/-83.703084,43.018999;-83.738798,43.018999\n",
      "CPU times: user 9.79 ms, sys: 0 ns, total: 9.79 ms\n",
      "Wall time: 69.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 520.9], [534.3, 0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Latitude,Longitude\n",
    "latlonglist = [\"-83.738798,43.018999\"] \n",
    "\n",
    "longstr = ''\n",
    "for i, c in enumerate(latlonglist):\n",
    "    if i == 0:\n",
    "        longstr = c\n",
    "    else:\n",
    "        longstr += ';' + c\n",
    "\n",
    "ip_add = \"54.144.55.140\"\n",
    "init_lat_long = \"-83.703084,43.018999\"\n",
    "how = \"driving\" #\"walking\" or \"driving\"\n",
    "url = f\"http://{ip_add}:5000/table/v1/{how}/{init_lat_long};{longstr}\"\n",
    "print(url)\n",
    "r = requests.get(url)\n",
    "output = r.json()\n",
    "#output['durations'] # output is in seconds\n",
    "output['durations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sixth-alarm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2727084, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(have_dists * 6371 < limit).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "likely-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TEST = 10000\n",
    "x = np.tril(np.ones(N_TEST**2).reshape(N_TEST, N_TEST) * 1e5)\n",
    "y = x + have_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "alpine-contrast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+05, 2.38114699e-05, 3.18948539e-05, ...,\n",
       "        4.42230932e-04, 4.41770459e-04, 3.88888651e-04],\n",
       "       [1.00000000e+05, 1.00000000e+05, 5.47877364e-05, ...,\n",
       "        4.63505730e-04, 4.61225399e-04, 4.10839840e-04],\n",
       "       [1.00000000e+05, 1.00000000e+05, 1.00000000e+05, ...,\n",
       "        4.10544135e-04, 4.11049448e-04, 3.57024383e-04],\n",
       "       ...,\n",
       "       [1.00000000e+05, 1.00000000e+05, 1.00000000e+05, ...,\n",
       "        1.00000000e+05, 6.71969822e-05, 6.03603816e-05],\n",
       "       [1.00000000e+05, 1.00000000e+05, 1.00000000e+05, ...,\n",
       "        1.00000000e+05, 1.00000000e+05, 1.05360468e-04],\n",
       "       [1.00000000e+05, 1.00000000e+05, 1.00000000e+05, ...,\n",
       "        1.00000000e+05, 1.00000000e+05, 1.00000000e+05]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "finished-blind",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1358542, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_idx = np.argwhere(y * 6371 < limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fossil-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(road_dist_arr > 0).sum(axis=1).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "otherwise-absence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road_dist_arr.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "israeli-highway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-revolution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
