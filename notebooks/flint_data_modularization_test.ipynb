{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from blue_conduit_spatial.data import build_datasets, load_datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape files truncate column names.  This dictionary is used to restore the whole names.\n",
    "\n",
    "col_name_dictionary = {'pid': 'pid', 'Property Z': 'Property Zip Code', 'Owner Type': 'Owner Type',\n",
    "                       'Owner Stat': 'Owner State', 'Homestead': 'Homestead', 'Homestea_1': 'Homestead Percent',\n",
    "                       'HomeSEV': 'HomeSEV', 'Land Value': 'Land Value', 'Land Impro': 'Land Improvements Value',\n",
    "                       'Residentia': 'Residential Building Value', 'Resident_1': 'Residential Building Style',\n",
    "                       'Commercial': 'Commercial Building Value', 'Building S': 'Building Storeys',\n",
    "                       'Parcel Acr': 'Parcel Acres', 'Rental': 'Rental', 'Use Type': 'Use Type',\n",
    "                       'Prop Class': 'Prop Class', 'Old Prop c': 'Old Prop class', 'Year Built': 'Year Built',\n",
    "                       'USPS Vacan': 'USPS Vacancy', 'Zoning': 'Zoning', 'Future Lan': 'Future Landuse',\n",
    "                       'DRAFT Zone': 'DRAFT Zone', 'Housing Co': 'Housing Condition 2012',\n",
    "                       'Housing _1': 'Housing Condition 2014', 'Commerci_1': 'Commercial Condition 2013',\n",
    "                       'Latitude': 'Latitude', 'Longitude': 'Longitude', 'Hydrant Ty': 'Hydrant Type',\n",
    "                       'Ward': 'Ward', 'PRECINCT': 'PRECINCT', 'CENTRACT': 'CENTRACT', 'CENBLOCK': 'CENBLOCK',\n",
    "                       'SL_Type': 'SL_Type', 'SL_Type2': 'SL_Type2', 'SL_Lead': 'SL_Lead', 'Ed_July': 'Ed_July',\n",
    "                       'Ed_March': 'Ed_March', 'Last_Test': 'Last_Test', 'Max_Lead': 'Max_Lead',\n",
    "                       'Med_Lead': 'Med_Lead', 'Num_Tests': 'Num_Tests', 'Res_Test': 'Res_Test',\n",
    "                       'Sen_Test': 'Sen_Test', 'SL_private': 'SL_private_inspection',\n",
    "                       'B_median_a': 'B_median_age_all_women', 'B_median_1': 'B_median_age_all_men', \n",
    "                       'B_median_2': 'B_median_age_all', 'B_median_3': 'B_median_age_all_women_white',\n",
    "                       'B_median_4': 'B_median_age_all_men_white', 'B_median_5': 'B_median_age_all_white',\n",
    "                       'B_median_6': 'B_median_age_all_women_black', 'B_median_7': 'B_median_age_all_men_black',\n",
    "                       'B_median_8': 'B_median_age_all_black', 'B_total_bl': 'B_total_black_pop',\n",
    "                       'B_total_wh': 'B_total_white_pop', 'B_married_': 'B_married_couples',\n",
    "                       'B_single_w': 'B_single_women', 'B_marrie_1': 'B_married_couples_white',\n",
    "                       'B_single_1': 'B_single_women_white', 'B_marrie_2': 'B_married_couples_black',\n",
    "                       'B_single_2': 'B_single_women_black', 'B_marrie_3': 'B_married_couples_w_children',\n",
    "                       'B_single_m': 'B_single_mothers_w_children', 'B_househol': 'B_households_w_elderly',\n",
    "                       'B_househod': 'B_househod_no_elderly', 'B_aggregat': 'B_aggregate_income',\n",
    "                       'B_speak_sp': 'B_speak_spanish', 'B_speak_on': 'B_speak_only_english',\n",
    "                       'B_no_engli': 'B_no_english', 'B_hispanic': 'B_hispanic_household',\n",
    "                       'B_imputed_': 'B_imputed_rent', 'B_impute_1': 'B_imputed_value',\n",
    "                       'known_priv': 'known_private_sl', 'known_publ': 'known_public_sl', 'hydrovac': 'hydrovac',\n",
    "                       'sl_priva_1': 'sl_private_type', 'sl_public_': 'sl_public_type', 'created_at': 'created_at',\n",
    "                       'source': 'source', 'hv_visit': 'hv_visit', 'sl_visit': 'sl_visit', 'replaced': 'replaced',\n",
    "                       'dangerous': 'dangerous', 'geometry': 'geometry'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update path to the new shapefile I sent.\n",
    "\n",
    "sl_df = gpd.read_file('../data/raw/flint_sl_materials/')\n",
    "sl_df = sl_df.rename(col_name_dictionary, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that aren't used by the classifier\n",
    "\n",
    "drop_cols = ['known_private_sl', 'known_public_sl', 'hydrovac', 'created_at', 'source',\n",
    "             'hv_visit', 'sl_visit', 'replaced', 'geometry', \n",
    "            'Latitude', 'Longitude']\n",
    "\n",
    "data = sl_df.drop(drop_cols, axis = 1)\n",
    "\n",
    "# Only keep labelled data\n",
    "data = data[~pd.isnull(data.dangerous)].reset_index()\n",
    "\n",
    "# Drop everything except target from training data\n",
    "Xdata = data.drop(['pid', 'sl_private_type', 'sl_public_type', 'dangerous'], axis = 1)\n",
    "\n",
    "# Build target.  Each 'dangerous' is True when sl_private_type OR sl_public_type contain lead.\n",
    "Ydata = data[['sl_private_type', 'sl_public_type', 'dangerous']]\n",
    "\n",
    "\n",
    "dummy_cols = ['Property Zip Code', 'Owner Type', 'Residential Building Style', 'Homestead', 'Building Storeys',\n",
    "              'Rental', 'Use Type', 'Prop Class', 'Old Prop class', 'USPS Vacancy', 'Housing Condition 2012',\n",
    "              'Housing Condition 2014', 'Owner State', 'Zoning', 'Future Landuse', 'Commercial Condition 2013',\n",
    "              'Hydrant Type', 'SL_Type', 'SL_Type2', 'DRAFT Zone', 'Last_Test', 'SL_private_inspection', 'Ward',\n",
    "              'CENTRACT', 'CENBLOCK']#, 'PRECINCT']\n",
    "\n",
    "# Fill missing data\n",
    "Xdata = Xdata.fillna(-1)\n",
    "\n",
    "# Create dummies from categorical columns\n",
    "Xdata = pd.get_dummies(Xdata, columns=dummy_cols)\n",
    "\n",
    "# Groups for spatial cross validation\n",
    "groups = Xdata['PRECINCT']\n",
    "Xdata = Xdata.drop('PRECINCT', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Shuffle Split example.  train_test_split could go here, but we like spatial cross validation \n",
    "# better than a uniform random sample.\n",
    "gss = GroupShuffleSplit(n_splits=3, train_size=.75, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in gss.split(Xdata, Ydata, groups):\n",
    "    train_index = train_idx\n",
    "    test_index = test_idx\n",
    "    break\n",
    "\n",
    "Xtrain = Xdata.loc[train_index]\n",
    "Xtest = Xdata.loc[test_index]\n",
    "Ytrain = Ydata.loc[train_index.tolist()]\n",
    "Ytest = Ydata.loc[test_index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blue_conduit_spatial.data import build_datasets, load_datasets\n",
    "\n",
    "def test_build(Xtrain, Xtest, Ytrain, Ytest):\n",
    "\n",
    "    data_dir = '../data'\n",
    "    data_raw_path = f'{data_dir}/raw/flint_sl_materials/'\n",
    "    save_dir = f'{data_dir}/test_dir'\n",
    "    Xtrain_, Xtest_, Ytrain_, Ytest_ = build_datasets(data_raw_path, save_dir=save_dir)\n",
    "    \n",
    "    assert Xtrain.drop('index', axis=1).equals(Xtrain_)\n",
    "    assert Xtest.drop('index', axis=1).equals(Xtest_)\n",
    "    assert Ytrain.equals(Ytrain_)\n",
    "    assert Ytest.equals(Ytest_)\n",
    "    \n",
    "def test_load(Xtrain, Xtest, Ytrain, Ytest):\n",
    "\n",
    "    data_dir = '../data'\n",
    "    save_dir = f'{data_dir}/test_dir'\n",
    "    \n",
    "    Xtrain = Xtrain.drop('index', axis=1).reset_index(drop=True)\n",
    "    Xtest = Xtest.drop('index', axis=1).reset_index(drop=True)\n",
    "    Ytrain = Ytrain.reset_index(drop=True)\n",
    "    Ytest = Ytest.reset_index(drop=True)\n",
    "    Ytrain['dangerous'] = Ytrain['dangerous'].astype(int)\n",
    "    Ytest['dangerous'] = Ytest['dangerous'].astype(int)\n",
    "    \n",
    "    Xtrain_, Xtest_, Ytrain_, Ytest_ = load_datasets(save_dir)\n",
    "    \n",
    "    assert Xtrain_.astype(Xtrain.dtypes).equals(Xtrain)\n",
    "    assert Xtest_.astype(Xtest.dtypes).equals(Xtest)\n",
    "    assert Ytrain_.astype(Ytrain.dtypes).equals(Ytrain)\n",
    "    assert Ytest_.astype(Ytest.dtypes).equals(Ytest)\n",
    "    \n",
    "test_build(Xtrain, Xtest, Ytrain, Ytest)\n",
    "test_load(Xtrain, Xtest, Ytrain, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an xgboost classifier\n",
    "data_dir = '../data'\n",
    "data_raw_path = f'{data_dir}/raw/flint_sl_materials/'\n",
    "save_dir = f'{data_dir}/processed'\n",
    "Xtrain, Xtest, Ytrain, Ytest = build_datasets(data_raw_path, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = xgboost.XGBClassifier()\n",
    "\n",
    "# xgb.fit(Xtrain, Ytrain['dangerous'])\n",
    "# yhat = xgb.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Measure predictive power.  This is roc score, but any metric could go here.\n",
    "# roc_auc_score(Ytest['dangerous'], yhat[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ADDED BY KEVIN HARE (9/26/2021)\n",
    "# import numpy as np\n",
    "# np.savez('../data/predictions/baseline_preds.npz', yhat=yhat, ytrue=Ytest['dangerous'])\n",
    "# xgb.save_model('../models/baseline_jared_20210921.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ac297r",
   "language": "python",
   "name": "ac297r"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
